import os
import sys
import json
import torch
import psutil
from pathlib import Path
from loguru import logger

class YouDubConfigOptimizer:
    """æ ¹æ®ç¡¬ä»¶é…ç½®è‡ªåŠ¨ä¼˜åŒ–YouDubå‚æ•°"""
    
    def __init__(self):
        self.config = {}
        self.detect_hardware()
        
    def detect_hardware(self):
        """æ£€æµ‹ç¡¬ä»¶é…ç½®"""
        logger.info("=" * 60)
        logger.info("[æ£€æµ‹] æ­£åœ¨æ£€æµ‹ç¡¬ä»¶é…ç½®...")
        logger.info("=" * 60)
        
        # GPU æ£€æµ‹
        self.gpu_available = torch.cuda.is_available()
        self.gpu_count = torch.cuda.device_count() if self.gpu_available else 0
        self.gpu_name = ""
        self.gpu_memory_gb = 0
        
        if self.gpu_available:
            for i in range(self.gpu_count):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                self.gpu_name = gpu_name
                self.gpu_memory_gb = gpu_memory
                logger.info(f"âœ… GPU {i}: {gpu_name}")
                logger.info(f"   æ˜¾å­˜: {gpu_memory:.1f} GB")
                logger.info(f"   CUDA: {torch.version.cuda}")
        else:
            logger.warning("âŒ æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼ï¼ˆé€Ÿåº¦ä¼šå¾ˆæ…¢ï¼‰")
        
        # CPU æ£€æµ‹
        self.cpu_count = psutil.cpu_count(logical=True)
        self.cpu_physical = psutil.cpu_count(logical=False)
        logger.info(f"âœ… CPU: {self.cpu_physical} ç‰©ç†æ ¸å¿ƒ / {self.cpu_count} é€»è¾‘æ ¸å¿ƒ")
        
        # å†…å­˜æ£€æµ‹
        self.total_memory_gb = psutil.virtual_memory().total / 1024**3
        logger.info(f"âœ… å†…å­˜: {self.total_memory_gb:.1f} GB")
        logger.info("=" * 60)
    
    def calculate_optimal_config(self):
        """æ ¹æ®ç¡¬ä»¶è®¡ç®—æœ€ä¼˜é…ç½®"""
        config = {
            "hardware": {
                "gpu_name": self.gpu_name,
                "gpu_memory_gb": self.gpu_memory_gb,
                "gpu_available": self.gpu_available,
                "cpu_cores": self.cpu_count,
                "memory_gb": self.total_memory_gb
            }
        }
        
        if not self.gpu_available:
            # CPU æ¨¡å¼ï¼ˆå¾ˆæ…¢ï¼‰
            config.update({
                "mode": "cpu",
                "resolution": "720p",
                "demucs_model": "htdemucs",
                "demucs_shifts": 0,
                "whisper_model": "small",
                "whisper_batch_size": 8,
                "whisper_diarization": False,
                "max_workers": 1,
                "force_bytedance": True,
                "expected_time_per_video": "20-30åˆ†é’Ÿ",
                "note": "æ— GPUï¼Œé€Ÿåº¦è¾ƒæ…¢ï¼Œå»ºè®®ä½¿ç”¨Bytedance TTSåŠ é€Ÿ"
            })
        elif self.gpu_memory_gb < 8:
            # ä½æ˜¾å­˜æ¨¡å¼ (< 8GB)
            config.update({
                "mode": "low_vram",
                "resolution": "1080p",
                "demucs_model": "htdemucs",
                "demucs_shifts": 0,
                "whisper_model": "small",
                "whisper_batch_size": 8,
                "whisper_diarization": False,
                "max_workers": 1,
                "force_bytedance": True,
                "expected_time_per_video": "8-12åˆ†é’Ÿ",
                "note": "æ˜¾å­˜è¾ƒä½ï¼Œä½¿ç”¨è½»é‡çº§æ¨¡å‹ç¡®ä¿å®‰å…¨è¿è¡Œ"
            })
        elif self.gpu_memory_gb < 12:
            # ä¸­ç­‰æ˜¾å­˜æ¨¡å¼ (8-12GB) - ä½ çš„RTX 4060åœ¨è¿™é‡Œ
            config.update({
                "mode": "balanced",
                "resolution": "1080p",
                "demucs_model": "htdemucs_ft",
                "demucs_shifts": 1,
                "whisper_model": "medium",
                "whisper_batch_size": 16,
                "whisper_diarization": False,
                "max_workers": 1,
                "force_bytedance": True,
                "expected_time_per_video": "6-10åˆ†é’Ÿ",
                "note": "æ¨èé…ç½®ï¼šå¹³è¡¡é€Ÿåº¦ä¸è´¨é‡ï¼Œé€‚åˆæ—¥å¸¸åˆ¶ä½œ"
            })
        elif self.gpu_memory_gb < 20:
            # é«˜æ˜¾å­˜æ¨¡å¼ (12-20GB)
            config.update({
                "mode": "high_performance",
                "resolution": "1080p",
                "demucs_model": "htdemucs_ft",
                "demucs_shifts": 2,
                "whisper_model": "large",
                "whisper_batch_size": 24,
                "whisper_diarization": True,
                "max_workers": 1,
                "force_bytedance": False,
                "expected_time_per_video": "10-15åˆ†é’Ÿ",
                "note": "å¯ä»¥å¼€å¯è¯´è¯äººåˆ†ç¦»ï¼Œä½¿ç”¨largeæ¨¡å‹è·å¾—æœ€ä½³è´¨é‡"
            })
        else:
            # é¡¶çº§é…ç½® (20GB+)
            config.update({
                "mode": "extreme",
                "resolution": "1080p",
                "demucs_model": "htdemucs_ft",
                "demucs_shifts": 2,
                "whisper_model": "large",
                "whisper_batch_size": 32,
                "whisper_diarization": True,
                "max_workers": 2,
                "force_bytedance": False,
                "expected_time_per_video": "8-12åˆ†é’Ÿï¼ˆå¹¶è¡Œå¤„ç†2ä¸ªè§†é¢‘ï¼‰",
                "note": "é¡¶çº§é…ç½®ï¼Œå¯åŒæ—¶å¤„ç†2ä¸ªè§†é¢‘"
            })
        
        self.config = config
        return config
    
    def print_config(self):
        """æ‰“å°é…ç½®å»ºè®®"""
        config = self.config
        
        print("\n" + "=" * 60)
        print("ğŸ¯ YouDub æœ€ä¼˜é…ç½®æ¨è")
        print("=" * 60)
        print(f"\nğŸ“Š æ£€æµ‹åˆ°çš„ç¡¬ä»¶:")
        print(f"   GPU: {config['hardware']['gpu_name'] or 'æ— '}")
        print(f"   æ˜¾å­˜: {config['hardware']['gpu_memory_gb']:.1f} GB")
        print(f"   å†…å­˜: {config['hardware']['memory_gb']:.1f} GB")
        print(f"   CPUæ ¸å¿ƒ: {config['hardware']['cpu_cores']}")
        
        print(f"\nâš™ï¸  æ¨èæ¨¡å¼: {config['mode'].upper()}")
        print(f"ğŸ“Œ é…ç½®è¯´æ˜: {config['note']}")
        print(f"â±ï¸  é¢„ä¼°è€—æ—¶: {config['expected_time_per_video']}/è§†é¢‘")
        
        print(f"\nğŸ“ Gradioç•Œé¢è®¾ç½®:")
        print(f"   Resolution:          {config['resolution']}")
        print(f"   Demucs Model:        {config['demucs_model']}")
        print(f"   Number of shifts:    {config['demucs_shifts']}")
        print(f"   Whisper Model:       {config['whisper_model']}")
        print(f"   Whisper Batch Size:  {config['whisper_batch_size']}")
        print(f"   Whisper Diarization: {config['whisper_diarization']}")
        print(f"   Max Workers:         {config['max_workers']}")
        print(f"   Force Bytedance:     {config['force_bytedance']}")
        
        print("\n" + "=" * 60)
        print("ğŸ’¡ æç¤º:")
        if config['whisper_diarization']:
            print("   â€¢ è¯´è¯äººåˆ†ç¦»å·²å¼€å¯ï¼Œå¦‚éœ€æ›´å¿«å¯å…³é—­")
        else:
            print("   â€¢ å¦‚éœ€è¯†åˆ«å¤šè¯´è¯äººï¼Œå¯æ‰‹åŠ¨å¼€å¯Diarizationï¼ˆä¼šæ›´æ…¢ï¼‰")
        if config['force_bytedance']:
            print("   â€¢ å·²æ¨èBytedance TTSï¼Œç¡®ä¿.envä¸­é…ç½®äº†APPIDå’ŒACCESS_TOKEN")
        if config['demucs_shifts'] > 0:
            print("   â€¢ å¦‚éœ€æ›´å¿«ï¼Œå¯å°†shiftsé™åˆ°0ï¼ˆè´¨é‡ç•¥é™ï¼‰")
        print("=" * 60 + "\n")
    
    def save_config(self):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        config_path = Path(__file__).parent.parent / "auto_config.json"
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, indent=2, ensure_ascii=False)
        logger.info(f"âœ… é…ç½®å·²ä¿å­˜åˆ°: {config_path}")
        return config_path
    
    def export_for_gradio(self):
        """å¯¼å‡ºGradioå¯ç”¨çš„é»˜è®¤å€¼"""
        config = self.config
        gradio_defaults = {
            "resolution": config['resolution'].replace('p', ''),
            "demucs_model": config['demucs_model'],
            "demucs_shifts": config['demucs_shifts'],
            "whisper_model": config['whisper_model'],
            "whisper_batch_size": config['whisper_batch_size'],
            "whisper_diarization": config['whisper_diarization'],
            "max_workers": config['max_workers'],
            "force_bytedance": config['force_bytedance']
        }
        return gradio_defaults

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 60)
    print("YouDub æ™ºèƒ½é…ç½®ä¼˜åŒ–å·¥å…·")
    print("=" * 60 + "\n")
    
    optimizer = YouDubConfigOptimizer()
    optimizer.calculate_optimal_config()
    optimizer.print_config()
    config_path = optimizer.save_config()
    
    # å¯¼å‡ºGradioé»˜è®¤å€¼
    gradio_config = optimizer.export_for_gradio()
    print("ğŸ“ Gradio é»˜è®¤å‚æ•°ï¼ˆå¯å¤åˆ¶åˆ°app.pyï¼‰:")
    print("-" * 60)
    for key, value in gradio_config.items():
        print(f"{key}: {value}")
    print("-" * 60)
    
    print(f"\nâœ… é…ç½®æ–‡ä»¶ä¿å­˜ä½ç½®: {config_path}")
    print("ğŸ’¡ ä½ å¯ä»¥åœ¨Gradioç•Œé¢ä¸­æŒ‰ä¸Šè¿°å‚æ•°è®¾ç½®ï¼Œ")
    print("   æˆ–ä¿®æ”¹app.pyä¸­çš„é»˜è®¤å€¼ä½¿å…¶è‡ªåŠ¨ç”Ÿæ•ˆã€‚\n")
    
    input("æŒ‰Enteré”®é€€å‡º...")

if __name__ == "__main__":
    main()
